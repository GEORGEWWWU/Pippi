# 皮皮蛛图片下载器 (Pippi Image Spider)

一款针对 `image.acg.lol` 站点开发的**稳健型图片爬虫工具**，支持交互式操作、智能去重、反反爬策略，可自动提取并下载目标页面中的指定图片，操作简单且下载稳定。

## 项目简介

本工具基于 `requests` + `BeautifulSoup` 开发，专为爬取 `image.acg.lol` 站点的 DSC 系列图片设计，兼顾易用性和健壮性：

- 自动识别页面中符合规则的图片链接，精准匹配目标资源
- 内置多重反反爬机制，降低被站点限制的概率
- 完善的文件去重逻辑，避免重复下载已保存图片
- 交互式命令行入口，支持自定义保存目录、多链接连续下载
- 详细的下载日志，实时展示下载/跳过/失败状态，清晰可控

## 核心特性

### 🛡️ 强力反反爬策略

1. 多 User-Agent 随机轮换，模拟不同浏览器请求
2. **全程无 Referer 请求头**（页面获取/图片下载均不携带），规避站点防盗链限制
3. 智能动态延迟：基础随机延迟 + 下载量递增延迟 + 每10张图片额外休息，请求更温和
4. 失败自动重试（默认3次），指数退避等待，提升请求成功率
5. 会话保持（`requests.Session`），减少连接建立开销

### 📂 智能文件管理

1. 自动创建保存目录（支持多级目录），无需手动新建
2. 优先提取图片原生 DSC 编号作为文件名，保持资源标识一致性
3. 备用哈希命名策略，避免无编号图片命名冲突
4. 双重去重校验：内存已下载集合 + 文件系统实际检测，彻底杜绝重复
5. 自动过滤小文件（<1KB），剔除无效损坏的图片资源

### 📊 完善的状态统计与日志

- 实时统计：新下载/已跳过/下载失败 图片数量
- 清晰的操作日志：成功（✓）、跳过（⏭️）、失败（❌）、调试（🔍）等状态标识
- 每10张图片自动休息提示，下载进度可视化
- 完成后输出详细汇总报告，清晰掌握下载结果

### ✨ 便捷交互与扩展

1. 全交互式命令行操作，支持默认值快速回车，新手友好
2. 支持自定义保存文件夹名称，自动清理文件夹名非法字符
3. 多链接连续下载，无需重启程序，提升批量爬取效率
4. 基础 URL 格式验证，避免无效输入
5. 备用图片提取方案：正则匹配失效时，自动使用 BeautifulSoup 兜底解析

## 环境依赖

本项目基于 Python 3.x 开发，核心依赖以下第三方库，需提前安装：

```bash
pip install requests beautifulsoup4
```

- `requests`：处理 HTTP 请求，支持会话保持、流式下载
- `beautifulsoup4`：HTML 解析，作为图片提取的备用方案

## 快速开始

### 1. 环境准备

确保已安装 **Python 3.6+** 和上述依赖库（执行上方 `pip install` 命令）。

### 2. 运行程序

将代码保存为 `pippi_spider.py`，在命令行执行：

```bash
python pippi_spider.py
```

### 3. 交互式操作

1. 输入爬取链接：直接回车使用默认示例链接，也可输入自定义目标链接（需以 `http://`/`https://` 开头）
2. 输入保存文件夹名：直接回车使用默认目录 `pippi_images`，自定义名称会自动清理非法字符
3. 确认下载：输入 `Y`/`是`/直接回车 确认开始，输入 `n` 取消
4. 连续下载：单链接下载完成后，可选择继续下载其他链接，无需重启程序

## 使用示例

```
============================================================
🕷️  欢迎使用皮皮蛛图片下载器
============================================================

💡 提示：直接回车将使用默认链接
   默认: https://bing.fullpx.com/

🔗 请输入要爬取的页面链接: https://xxx.acg.lol/xxx
✓ 已输入链接: https://xxx.acg.lol/xxx

💡 提示：直接回车将使用默认文件夹 'pippi_images'
📁 请输入保存文件夹名称: my_acg_images
✓ 保存至文件夹: my_acg_images

------------------------------------------------------------
📋 下载信息确认:
   目标链接: https://xxx.acg.lol/xxx
   保存目录: /xxx/xxx/my_acg_images
------------------------------------------------------------
🚀 确认开始下载? [Y/n]: y

============================================================
🚀 爬取: https://xxx.acg.lol/xxx
📁 目录: /xxx/xxx/my_acg_images
============================================================

📂 发现 0 个已下载的文件，将自动跳过
🔍 调试：找到 25 个匹配
🎯 共 25 张图片，开始下载...

  ✓ [1] DSC1234.jpg (2048.5 KB)
  ✓ [2] DSC1235.jpg (1987.2 KB)
  ...
  💤 休息 4.2 秒...
  ✓ [11] DSC1244.jpg (2105.8 KB)
  ...
  ⏭️  [15] DSC1248.jpg (已存在)

============================================================
✅ 完成: 新下载 23, 跳过 2, 失败 0
============================================================

============================================================
🔄 是否继续下载其他链接? [y/N]: n
👋 感谢使用，再见！

按回车键退出...
```

## 核心功能说明

### 图片提取规则

- 主规则：通过正则精准匹配 `image.acg.lol` 站点的 DSC 系列图片链接（格式：
  `https?://image\.acg\.lol/file/\d{4}/\d{2}/\d{2}/DSC\d+\.jpg`）
- 兜底规则：若正则匹配无结果，自动使用 BeautifulSoup 解析页面中所有包含 `acg.lol` 的图片链接，保证资源不丢失

### 文件名生成逻辑

1. 优先提取图片链接中的 DSC 数字编号，生成如 `DSC1234.jpg` 的文件名，保持与源站一致
2. 若无法提取 DSC 编号，使用**URL 哈希值+索引**生成文件名（如 `img_0001_8f2d45.jpg`），避免命名冲突

### 下载策略

- 流式下载图片，分块写入文件，支持大图片下载，避免内存溢出
- 下载前验证文件是否存在，存在则直接跳过并计数
- 下载后验证文件大小（<1KB 判定为无效），自动删除损坏文件并标记失败
- 每下载10张图片随机休息 3-6 秒，降低服务器访问压力

## 注意事项

1. **合规爬取**：请仅用于爬取授权的公开资源，遵守目标站点的 `robots.txt` 协议和相关法律法规，请勿恶意爬取或滥用
2. **速率限制**：工具已内置智能延迟，请勿自行修改删除延迟逻辑，避免给目标服务器造成压力，导致IP被限制
3. **资源专属**：本工具为 `image.acg.lol` 站点的 DSC 系列图片定制，其他站点可能无法正常提取图片
4. **异常处理**：若出现大量下载失败，可能是目标站点限制了你的IP，可暂停一段时间后再尝试，或更换网络环境
5. **日志查看**：程序运行过程中的调试信息、状态提示可帮助排查问题（如“未找到图片”可检查目标链接是否正确）

## 项目结构

核心类 `RobustImageSpider` 封装所有爬虫逻辑，模块化设计便于维护和扩展：

- `__init__`：初始化配置（目录、会话、User-Agent、计数器等）
- `get_page`：获取目标页面源码，带重试和随机UA
- `extract_images`：提取图片链接，主正则+备用BeautifulSoup
- `download_image`：下载单张图片，流式写入+文件验证+动态延迟
- `crawl`：爬虫主流程，串联页面获取-链接提取-图片下载
- 辅助方法：文件去重、文件名生成、随机延迟等

交互式入口由 `main()` 函数驱动，串联 `get_user_input`/`get_folder_name`/`confirm_download` 等交互方法，提供友好的用户体验。

## 异常处理

程序内置完善的异常捕获机制，可处理常见问题：

- 网络异常：请求超时、连接失败等，自动重试并输出提示
- 输入异常：非法URL、无效文件夹名等，给出引导并重新输入
- 文件异常：文件已存在、写入失败、小文件等，自动跳过或清理
- 用户中断：按 `Ctrl+C` 可安全退出，无资源泄露
- 其他未知异常：捕获并输出错误信息，避免程序崩溃