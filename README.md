# 🕷️ 皮皮蛛 (PippiSpider)

一只懂得休息、会跳过已下载、绝不给主人添麻烦的乖蜘蛛。

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## ✨ 特性

- 🚀 **断点续传** - 自动检测已下载文件，随时中断随时继续
- 🛡️ **智能反爬** - 动态延迟、User-Agent轮换、请求频率控制
- 🎯 **万能提取** - 支持任意格式（JPG/PNG/WEBP/GIF等），不限于特定前缀
- 📁 **智能命名** - 自动保留原始文件名，自动清理非法字符
- 🖥️ **交互友好** - 命令行交互式输入，支持循环下载多个链接
- 🔧 **零配置** - 开箱即用，无需修改代码

## 📦 安装依赖

```bash
pip install requests beautifulsoup4
```

## 🚀 快速开始

### 运行程序

```bash
python main.py
```

### 交互流程

```
============================================================
🕷️  欢迎使用皮皮蛛图片下载器
   支持任意格式: JPG PNG WEBP GIF 等
============================================================

💡 提示：直接回车使用默认链接
   默认: https://bing.fullpx.com/

🔗 请输入要爬取的页面链接: [输入URL或直接回车]

💡 提示：直接回车使用默认文件夹 'pippi_images'
📁 请输入保存文件夹名称: [输入文件夹名或直接回车]

📋 下载信息确认:
   目标链接: https://...
   保存目录: F:\...\pippi_images
------------------------------------------------------------
🚀 确认开始下载? [Y/n]: 
```

## ⚙️ 配置说明

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `pippi_images` | str | `"pippi_images"` | 图片保存目录 |
| `min_delay` | float | `1.5` | 最小请求延迟(秒) |
| `max_delay` | float | `5.0` | 最大请求延迟(秒) |
| `retries` | int | `3` | 失败重试次数 |

## 🛡️ 反爬策略

皮皮蛛采用以下策略避免被封：

1. **随机延迟** - 基础延迟1.5秒，随下载数量递增（最大5秒）
2. **UA轮换** - 3个不同浏览器的User-Agent随机切换
3. **无Referer** - 严格遵守目标站要求，不添加Referer头
4. **批量休息** - 每下载10张自动休息3-6秒
5. **指数退避** - 请求失败时采用指数退避重试

## 🎯 图片提取策略

| 优先级 | 方法 | 说明 |
|--------|------|------|
| 1 | 通用正则 | 匹配所有常见图片格式链接 |
| 2 | CDN专用正则 | 针对acg.lol等特定CDN优化 |
| 3 | BeautifulSoup | 解析懒加载、data-src等属性 |
| 4 | 懒加载正则 | 匹配背景图、延迟加载图片 |

支持的格式：`.jpg` `.jpeg` `.png` `.webp` `.gif` `.bmp` `.tiff`

## 📁 项目结构

```
pippi-spider/
├── main.py    # 主程序
├── README.md          # 本文件
└── pippi_images/ # 默认下载目录
    ├── photo_01.png
    ├── img_0001_a3f7.jpg
    └── ...
```

## 🎮 运行示例

```
📂 发现 20 个已下载的文件，将自动跳过

============================================================
🚀 爬取: https://bing.fullpx.com/
📁 目录: F:\project\pippi-spider\pippi_images
============================================================

🔍 找到 50 个图片链接
   示例: https://bing.fullpx.com/ph001.jpg
🎯 共 50 张图片，开始下载...

  ⏭️  [1] ph001.jpg (已存在)
  ⏭️  [2] ph002.jpg (已存在)
  ...
  ✓ [21] ph003.jpg (856.3 KB)
  ✓ [22] photo_01.png (1024.5 KB)
💤 休息 4.2 秒...
  ✓ [23] DSC_1.jpg (768.2 KB)

============================================================
✅ 完成: 新下载 30, 跳过 20, 失败 0
============================================================

🔄 是否继续下载其他链接? [y/N]:
```

## ⚠️ 注意事项

1. **合法使用** - 请确保你有权下载目标网站的图片
2. **控制频率** - 即使有多重保护，也不要短时间内大量下载
3. **磁盘空间** - 确保下载目录有足够空间
4. **网络稳定** - 建议使用稳定的网络环境

## 🔧 故障排除

### 找不到图片链接
- 检查目标URL是否可访问
- 检查网页是否需要登录或特殊权限
- 尝试查看网页源代码确认图片链接格式

### 下载失败
- 检查网络连接
- 增加延迟时间（修改 `_get_random_delay` 参数）
- 查看是否有IP被封（暂停几小时后重试）

### 文件名乱码
- 程序已自动处理URL编码，如遇问题请检查系统编码设置

## 📝 更新日志

### v1.0.0
- ✨ 支持交互式输入URL
- ✨ 支持任意图片格式提取
- ✨ 智能文件名处理
- ✨ 断点续传功能
- ✨ 循环下载多个链接

## 📜 开源协议

MIT License - 自由使用，后果自负 😄

---

Made with 🕸️ by [GEORGEWU](https://georgewu.top)